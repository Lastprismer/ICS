# Cache Memories

[TOC]



## 高速缓存的组织和运行

<img src="./Images/12-Memory Hierarchy Pyramid.png" style="zoom: 80%;" />



### 组织架构

*高速缓存*：cache，作为存储在更大、也更慢的设备中的数据对象的缓冲区域；使用高速缓存的过程叫*缓存*

中心思想：对于每个 $k$，位于 $k$ 层的更小、更快的存储设备作为位于 $k+1$ 层的更大更慢的存储设备的缓存

<img src="./Images/13-General Cache Concept.png" style="zoom: 67%;" />

* 第 $k+1$ 层的存储器被划分称连续地数据对象组块（chunk），简称为块（block），每个块都有唯一的地址或名字。
* 块通常是固定大小的，也有可变大小的（存储在Web服务器上的远端文件）。
* 第 $k$ 层的存储器被划分为较小的块的集合，每个块的大小和 $k+1$ 层的块的大小一样。第 $k$ 层的缓存包含第 $k+1$ 层块的一个子集的副本。
* 为了划分，得数据对齐
* L1和L0为1个字，L2与L1、L3与L2、L4与L3为64字节



### 缓存命中

当程序需要第 $k+1$ 层的某个数据对象 $d$ 时，它首先在当前存储在第 $k$ 层的一个块中查找 $d$。

* **缓存命中**：$d$ 刚好缓存在第 $k$ 层中，程序直接从第 $k$ 层读取 $d$。这要比从第 $k+1$ 层读取更快。

* **缓存不命中**：第 $k$ 层中没有 $d$。第 $k$ 层的缓存从 $k+1$ 层缓存中取出包含 $d$ 的那个块，如果第 $k$ 层的缓存已满，则覆盖现存的一个块。

  * *放置策略*：从 $k+1$ 层中取出的块放在哪里
  * *替换策略*：如果要覆盖，覆盖哪一个块（牺牲）

  缓存不命中的种类：

  1. 冷不命中：第 $k$ 层的缓存是空的，强制性不命中
  2. 容量不命中：*缓存太小*，不能处理工作集
  3. 冲突不命中：*缓存足够大*，但是由于放置策略，数据对象会重复映射到同一个缓存块



### 通用的cache组织结构

<img src="./Images/13-Typical System Structure.png" style="zoom:50%;" />

* 小、快的SRAM存储器，CPU会首先在高速缓存中寻找数据

  L1与CPU：约4时钟周期；L2与L1：10；L3与L2：50

  

<img src="./Images/13-General Cache Organization.png" style="zoom:67%;" />

* 假设一个计算机，存储器地址有 $m$ 位，形成 $M=2^m$ 个不同的地址 ；

*地址如何和高速缓存一一对应？*

* 高速缓存被组织为一个有 $S=2^s$个 **高速缓存组** 的数组
* 每个组包含 $E$ 个 **高速缓存行**
* 每个行里有一个 $B=2^b$ 字节的 **数据块**、一个指明这个行的信息是否有意义的 **有效位**、$t=m-(b+s)$ 的 **标记位**（行索引）

*地址信息如何分划？*

* 一共 $m$ 位
* 高地址 $t$ 位是 **标记位**，中间的 $s$ 位是 **组索引**，低地址 $b$ 位是 **块偏移**
* 组索引为无符号整数，指出字存于哪个组中；标记位 $t$ 表示组中的哪一行包含这个字；$b$ 个块偏移指出这个位置在 $B$ 个字节的数据块中的字偏移

高速缓存的大小 $C$ ：$C=S \times E \times B$

<img src="./Images/13-Cache Parameters.png" style="zoom:67%;" />

人话：

* 块：**信息包**
* 行：**容器**，存着块
* 组：**装着行的容器**



### 直接映射高速缓存

直接映射高速缓存：每个组只有1行（$E=1$）的高速缓存，作为例子

假设4位的地址，$t=1, s=2,b=1$

地址：0011

0. 相关分析：内存大小 $2^4=16$，四个组，每组一行，每块 $2$ 字节
1. **组选择**：组索引为01，选择第一组
2. **行匹配**：只有一行
   1. 有效位必须设置
   2. 行中的标记位必须和地址中的标记位相匹配
3. **字选择**：如果命中（2中匹配成功且有效），计算块偏移位。此处块偏移为 $1_2=1$，则这个内存是从块中的字节 $1$ 开始的
4. 不命中时的**行替换**：将取出的块存储在组索引位指示的组中的一行
   * 直接映射替换策略：直接替换该行
5. **冲突不命中**：当程序访问大小位2的幂的数组时，直接映射高速缓存中通常会发生冲突不命中：一个数组刚好占满高速缓存，导致**抖动**
6. 用中间的位做组索引：防止连续的内存映射到同一个组中





### 组相联高速缓存

概念：$1<E<C/B$ 的高速缓存：$E$ 路组相联高速缓存

1. 组选择：组索引位标识组
2. 行匹配：遍历组中每一行，找到标记位匹配的行
3. 字选择：一样
4. 不命中时的行替换：*最不常使用*（LFU，过去使用次数最少），*最近最少使用*（LRU，最后一次访问最久远）



### 全相联高速缓存

概念：$E=C/B$，一个组内包含了所有的行

1. 组选择：平凡（地址中没有组索引位，只有一个标记和一个块偏移）
2. 行匹配、字选择、不命中的行替换：和组相联一样
3. 补充：贵、难构造，只适合做小的高速缓存：虚存系统中的*翻译备用缓冲器*（TLB）



### 写

已经命中：

* **直写**（write-through）：立即将这个高速缓存块写回到内存中
  * 缺点：每次写都会引起总线流量
* **写回**（write-back）：不立即写回；当这个块要被驱逐时，才把它写到紧接着的低一层中（记录改变，一次实现）
  * 优点：显著减少总线流量
  * 缺点：增加复杂性，每一个高速缓存行都要维护一个额外的*修改位*（dirty bit），表明是否修改过

没有命中：

* **写分配**（write-allocate）：将低一层的块加载进高速缓存，在高速缓存行中更改
  * 缺点：每次不命中都会传送一次；
  * 如果这个位置要被写多次，那是好的且几乎没有坏处
* **非写分配**（not-write-allocate）：避开高速缓存，直接将这个字写到低一层中

典型情况：

* 写回+写分配
* 直写+非写分配



### 真实的高速缓存

<img src="./Images/13-Intel i7 Cache.png" style="zoom:67%;" />

<img src="./Images/13-Intel i7 Cache2.png" style="zoom:67%;" />

* 高速缓存既保存指令又保存程序数据数据，只保存指令i-cache，只保存数据d-cache，两个都保存unified cache（统一高速缓存）

* i-cache通常只读

  例：L1 d-cache，$S=\frac{C}{BE}=64,s=6$，6组索引、6位偏移、35标记位





### 高速缓存参数的性能影响

* **不命中率**：不命中数量/引用数量，L1约为 $3\%-10\%$ ，后面的小得多（取决于大小）
  * **命中率**
* **命中时间**：从高速缓存传送一个字到CPU所需的时间，包含组选择、行确认和字选择的时间
* **不命中处罚**：不命中需要的额外的时间，L1-L2为10+，L2-L3为50，L3-主存为200

优化高速缓存的考量：

* 高速缓存大小：大$\rightarrow$命中率高，但命中时间增加
* 块大小：大$\rightarrow$利用空间局部性，提高命中率；但降低高速缓存行数，损害时间局部性比空间局部性好的程序的命中率；块越大传送时间越长
* 相联度：大$\rightarrow$降低抖动可能性，但昂贵且慢、复杂，命中时间和不命中处罚的折中
* 写策略：层次低，写回更多；直写高速缓存更容易实现（*写缓冲区*辅助更新内存）





### 写高速缓存友好的代码

1. 让最常见的情况运行的快
2. 关注内循环：对局部变量的反复引用、步长为1的引用模式





## 高速缓存对程序性能的影响



### 存储器山

* **读吞吐量**：程序从存储系统中读数据的速率，读带宽，单位MB/s
* 测量存储系统性能：从一个紧密程序循环中发出一系列请求，测量读吞吐量

```c
long data[MAXELEMS]; /* Global array to traverse */

/* test - 以步长为"stride"扫描"data"数组的头"elems"个元素
* 使用4x4循环展开
*/
int test(int elems, int stride) {
    long i, sx2=stride*2, sx3=stride*3, sx4=stride*4;
    long acc0 = 0, acc1 = 0, acc2 = 0, acc3 = 0;
    long length = elems, limit = length - sx4;
    /* 4*4展开 */
    for (i = 0; i < limit; i += sx4)
    {
        acc0 = acc0 + data[i];
        acc1 = acc1 + data[i+stride];
        acc2 = acc2 + data[i+sx2];
        acc3 = acc3 + data[i+sx3];
    }
    /* 处理剩余的元素 */
    for (; i < length; i += stride)
    {
        acc0 = acc0 + data[i];
    }
    return ((acc0 + acc1) + (acc2 + acc3));
}

/* run - 执行test(elems, stride)，返回读吞吐量(MB/s)。
* "size"以字节为单位, "stride"是遍历数组元素的步长, Mhz是
* 估算的CPU频率，单位为Mhz
*/
double run(int size, int stride, double Mhz) 
{ 
    double cycles; 
    int elems = size / sizeof(double); 

    test (elems, stride);                    /* 预热高速缓存，避免冷不命中 */ 
    cycles = fcyc2(test, elems, stride, 0);  /* 运行test(elems,stride) */ 
    return (size / stride) / (cycles / Mhz); /* 将循环转化为MB/s */
} 
```

<img src="./Images/13-Memory Mountain.png" style="zoom:67%;" />

* 四条山脊：L1、L2、L3、主存内的时间局部性区域
* 空间局部性斜坡：随着步长增加，空间局部性下降；主存最高点比最低点高得多：程序时间局部性很差时，空间局部性仍然能补救
* 步长为1时，L1到L3这段都很高的原因：Core i7的**预取**（prefetching）机制：会自动识别顺序的、步长为1的引用模式，试图在某些块在被访问之前，将它们取到高速缓存中

<img src="./Images/13-Memory Mountain Slice.png" style="zoom:67%;" />

* 高速缓存的大小和时间局部性对性能的影响：

  大小最大为32KB的工作集完全能放进L1 d-cache中，吞吐量很高；

  256KB放进L2中，8MB放进L3中，更大的在主存中

* 256KB和8MB的下降：不知道，可能与其他数据或代码行的冲突有关

<img src="./Images/13-Memory Mountain Slice2.png" style="zoom:67%;" />

* 4MB时，工作集能放进L3中，但是对L2来说太大了
* s1到s8吞吐量平稳下降：步长增加，L2中不命中率增加；s8后步长增加，每个读都不会命中（一步跨越超过64位），必须从L3服务



### 重新排列循环以提高空间局部性

例：矩阵乘法：

最优方案：

```c
for (k = 0; k < n; k++)
    for (i = 0; i < n; i++)
    {
        r = A[i][k];
        for (j = 0; j < n; j++) // 分析这个内循环
            C[i][j] += r * B[i][j]; // 步长为1
    }
```

